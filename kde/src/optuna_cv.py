
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: research/optuna_cv.ipynb
import matplotlib.pyplot as plt
import numpy as np
from functools import partial

def _objective_kde_best_bw(trial, x1d=None):
    from sklearn.neighbors import KernelDensity
    from sklearn.model_selection import train_test_split

    # hyper parameter
    bandwidth = trial.suggest_float('bw', 0, 1)
    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')

    # cross validation
    assert x1d is not None, 'Dataset is not provided'
    X = x1d[:, None]
    x_train, x_test = train_test_split(X, test_size = 0.8)

    # fit
    kde.fit(x_train)

    # loss function to minimize
    loglikelihood = kde.score_samples(x_test)
    # minimize the negative log loss of the likelihood
    #    'AND' of sample's probs should account the same
    #    thus, joint prob they all match
    #    negate to minimize objective
    neglogloss = -1 * np.sum(loglikelihood)
    return neglogloss

def estimate_kde(x1d, return_study=False):
    import optuna
    optuna.logging.set_verbosity(optuna.logging.WARNING)

    # attach dataset to objective
    objective = partial(_objective_kde_best_bw, x1d=x1d)

    # search
    study = optuna.create_study()
    study.optimize(objective, n_trials=400)

    # instantiate and fit the KDE model
    from sklearn.neighbors import KernelDensity
    bandwidth=study.best_params['bw'] # E.g. {'x': 2.002108042}
    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')
    kde.fit(x1d[:, None])

    if return_study:
        return kde, study
    else:
        return kde

def plot_kde(kde, linspace, x=None):
    # score_samples returns the log of the probability density
    linspace = np.linspace(-4, 8, 1000)
    logprob = kde.score_samples(linspace[:, None])

    plt.fill_between(linspace, np.exp(logprob), alpha=0.5)
    if x is not None:
        plt.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)
    # plt.ylim(-0.02, 0.4)

def cdf_from_kde(kde, linspace):
    logprob = kde.score_samples(linspace[:, None])
    cdf_raw=np.exp(logprob).cumsum()
    cdf=cdf_raw/cdf_raw[-1] #normalize

    return cdf

def pval_from_cdf(x, cdf, linspace):
    if x >= linspace[-1]:
        # higher value that we ever seen
        return 1.0
    else:
        idx=np.argmax(linspace>x)
        return cdf[idx]